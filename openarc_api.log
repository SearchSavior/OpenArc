2025-05-13 18:55:37,638 - optimum_api - INFO - POST /optimum/model/load called with load_config: id_model='/mnt/Ironwolf-4TB/Models/OpenVINO/Qwen3-0.6B-fp16-ov' model_type=<ModelType.TEXT: 'TEXT'> use_cache=True device='GPU.1' export_model=False dynamic_shapes=True pad_token_id=None eos_token_id=None bos_token_id=None, ov_config: NUM_STREAMS='1' PERFORMANCE_HINT='LATENCY' INFERENCE_PRECISION_HINT=None ENABLE_HYPER_THREADING=None INFERENCE_NUM_THREADS=None SCHEDULING_CORE_TYPE=None
2025-05-13 18:57:08,849 - optimum_api - INFO - POST /optimum/model/load called with load_config: id_model='/mnt/Ironwolf-4TB/Models/OpenVINO/Qwen3-0.6B-fp16-ov' model_type=<ModelType.TEXT: 'TEXT'> use_cache=True device='GPU.1' export_model=False dynamic_shapes=True pad_token_id=None eos_token_id=None bos_token_id=None, ov_config: NUM_STREAMS='1' PERFORMANCE_HINT='LATENCY' INFERENCE_PRECISION_HINT=None ENABLE_HYPER_THREADING=None INFERENCE_NUM_THREADS=None SCHEDULING_CORE_TYPE=None
2025-05-13 18:58:43,070 - src.api.optimum_api - INFO - POST /optimum/model/load called with load_config: id_model='/mnt/Ironwolf-4TB/Models/OpenVINO/Qwen3-0.6B-fp16-ov' model_type=<ModelType.TEXT: 'TEXT'> use_cache=True device='GPU.1' export_model=False dynamic_shapes=True pad_token_id=None eos_token_id=None bos_token_id=None, ov_config: NUM_STREAMS='1' PERFORMANCE_HINT='LATENCY' INFERENCE_PRECISION_HINT=None ENABLE_HYPER_THREADING=None INFERENCE_NUM_THREADS=None SCHEDULING_CORE_TYPE=None
2025-05-13 19:08:40,182 - src.api.optimum_api - INFO - POST /optimum/model/load called with load_config: id_model='/mnt/Ironwolf-4TB/Models/OpenVINO/Qwen3-0.6B-fp16-ov' model_type=<ModelType.TEXT: 'TEXT'> use_cache=True device='GPU.1' export_model=False dynamic_shapes=True pad_token_id=None eos_token_id=None bos_token_id=None, ov_config: NUM_STREAMS='1' PERFORMANCE_HINT='LATENCY' INFERENCE_PRECISION_HINT=None ENABLE_HYPER_THREADING=None INFERENCE_NUM_THREADS=None SCHEDULING_CORE_TYPE=None
2025-05-13 19:30:04,415 - optimum.intel.openvino.modeling_base - INFO - Compiling the model to GPU.1 ...
2025-05-13 19:30:04,415 - optimum.intel.openvino.modeling_base - INFO - Setting OpenVINO CACHE_DIR to /mnt/Ironwolf-4TB/Models/OpenVINO/Qwen3-0.6B-fp16-ov/model_cache
2025-05-13 19:38:04,576 - src.api.optimum_api - INFO - POST /optimum/model/load called with load_config: id_model='/mnt/Ironwolf-4TB/Models/OpenVINO/Qwen3-0.6B-fp16-ov' model_type=<ModelType.TEXT: 'TEXT'> use_cache=True device='GPU.1' export_model=False dynamic_shapes=True pad_token_id=None eos_token_id=None bos_token_id=None, ov_config: NUM_STREAMS='1' PERFORMANCE_HINT='LATENCY' INFERENCE_PRECISION_HINT=None ENABLE_HYPER_THREADING=None INFERENCE_NUM_THREADS=None SCHEDULING_CORE_TYPE=None
