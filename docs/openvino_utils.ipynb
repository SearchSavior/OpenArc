{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenVINO Utilities Notebook\n",
    "\n",
    "Various utilities live in this notebook to help users of OpenArc understand the properties of their devices; mastering understanding of available data types, quantization strategies and  available optimization techniques is only one part of learning to use OpenVINO on different kinds of hardware.\n",
    "\n",
    "OpenArc does some of the work of serving inference but is opinionated in areas of the approach; OpenArc doesn't hand hold like other Intel applications like [Intel AI Playground](https://github.com/intel/AI-Playground) which are more entry-level-plug-and-play.\n",
    "\n",
    "Thanks again for checking out my project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to working with Intel Devices\n",
    "\n",
    "This document offers discussion of \"lessons-learned\" from months of working with Intel GPU devices; *hours* of blood, sweat, and tears went into setting up this project and it's a good place to share what I've learned. At this stage in the Intel AI Stack it seems like a neccessary contribution to the community.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to working with Intel Devices\n",
    "\n",
    "This document offers discussion of \"lessons-learned\" from months of working with Intel GPU devices; *hours* of blood, sweat, and tears went into setting up this project and it's a good place to share what I've learned. At this stage in the Intel AI Stack it seems like a neccessary contribution to the community.\n",
    "\n",
    "### What is OpenVINO?\n",
    "\n",
    "OpenVINO is an inference backend for *acclerating* inference deployments of machine learning models on Intel hardware. It can be hard to understand the documentation- the Intel AI stack has many staff engineers/contributors to all manner of areas in the open source ecosystem and much of the stack is evolving without massive community contributions like what we have seen with llama.cpp. \n",
    "\n",
    "Many reasons contribute to the decline of Intel's dominance/popularity in the hardware space in the past few years; however they offer extensive open source contributions to many areas of AI, ML and have been since before [Attention Is All You Need](https://arxiv.org/abs/1706.03762). AI didn't start in 2017- however the demand for faster inference on existing infrastructure has never been higher. Plus, Arc chips are cheap but come with a steep learning curve. Sure, you can settle for Vulkan... but you aren't here to download a GGUF and send it.  \n",
    "\n",
    "\n",
    "\n",
    "### OpenVINO Utilities\n",
    "\n",
    "Various utilities live in this notebook to help users of OpenArc understand the properties of their devices; mastering understanding of available data types, quantization strategies and  available optimization techniques is only one part of learning to use OpenVINO on different kinds of hardware.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Check out the [Guide to the OpenVINO IR] and then use my [Command Line Tool tool](https://huggingface.co/spaces/Echo9Zulu/Optimum-CLI-Tool_tool) to perform converion. There are default approachs that \"work\" but to really leverage available compute you have to dig deeper and convert models yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic: Device Query\n",
    "\n",
    "\n",
    "Reveals:\n",
    "    - Driver issues\n",
    "    - Device access permissions\n",
    "    - Hardware access from containers\n",
    "    - Python path visibility\n",
    "    - Proper environment variable configuration \n",
    "\n",
    "#### Example use cases:\n",
    "\n",
    "1. Evaluating conflicting dependencies\n",
    "    - With careful dependency management you can control hardware across the Intel AI stack.\n",
    "    - However \n",
    "\n",
    "\n",
    "2. Say you need to have PyTorch, IPEX and OpenVINO in one conda env.\n",
    "    - This test WITH alongside an XPU device query creates useful diagnostic infomration. \n",
    "    - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic Device Query\n",
    "\n",
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "available_devices = core.available_devices\n",
    "\n",
    "print(available_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding your device\n",
    "\n",
    "Working with OpenVINO requires understanding facts about your device.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Query: \n",
    "\n",
    "\n",
    "# Taken from https://github.com/openvinotoolkit/openvino/blob/master/samples/python/hello_query_device/hello_query_device.py\n",
    "\n",
    "import logging as log\n",
    "import sys\n",
    "\n",
    "import openvino as ov\n",
    "\n",
    "\n",
    "def param_to_string(parameters) -> str:\n",
    "    \"\"\"Convert a list / tuple of parameters returned from OV to a string.\"\"\"\n",
    "    if isinstance(parameters, (list, tuple)):\n",
    "        return ', '.join([str(x) for x in parameters])\n",
    "    else:\n",
    "        return str(parameters)\n",
    "\n",
    "\n",
    "def main():\n",
    "    log.basicConfig(format='[ %(levelname)s ] %(message)s', level=log.INFO, stream=sys.stdout)\n",
    "\n",
    "    # --------------------------- Step 1. Initialize OpenVINO Runtime Core --------------------------------------------\n",
    "    core = ov.Core()\n",
    "\n",
    "    # --------------------------- Step 2. Get metrics of available devices --------------------------------------------\n",
    "    log.info('Available devices:')\n",
    "    for device in core.available_devices:\n",
    "        log.info(f'{device} :')\n",
    "        log.info('\\tSUPPORTED_PROPERTIES:')\n",
    "        for property_key in core.get_property(device, 'SUPPORTED_PROPERTIES'):\n",
    "            if property_key not in ('SUPPORTED_PROPERTIES'):\n",
    "                try:\n",
    "                    property_val = core.get_property(device, property_key)\n",
    "                except TypeError:\n",
    "                    property_val = 'UNSUPPORTED TYPE'\n",
    "                log.info(f'\\t\\t{property_key}: {param_to_string(property_val)}')\n",
    "        log.info('')\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------------------------\n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sys.exit(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenVINO-Transformers-Chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
