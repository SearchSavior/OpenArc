

import logging

from transformers import AutoTokenizer
from optimum.intel.openvino import OVModelForCausalLM

from src2.server.model_registry import ModelLoadConfig






class Optimum_VLM:
    def __init__(self, load_config: ModelLoadConfig):
        pass
    def generate_type():
        pass

    def prepare_inputs():
        pass

    async def generate_text():
        pass

    async def generate_stream():
        pass

    def collect_metrics():
        pass

    def load_model():
        pass

    async def unload_model():
        pass